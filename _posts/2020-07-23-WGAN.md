---
layout: post
title: WGAN
date: 2020-07-23
tags: 深度学习 GAN
---

# WGAN

Wasserstein GAN：使用了Wasserstein Distance又叫EM(Earth-Mover)距离、

|      |                        Discriminator                         |                         Generator                          |
| :--: | :----------------------------------------------------------: | :--------------------------------------------------------: |
| GAN  | $\nabla_{\theta_d}\frac{1}{m}\sum_{i=1}^m[{\rm log}D(x^{(i)}+{\rm log}(1-D(G(z^{(i)})))]$ | $\nabla_{g}\frac{1}{m}\sum_{i=1}^m-{\rm log}D(G(z^{(i)}))$ |
| WGAN | $\nabla_{w}\frac{1}{m}\sum_{i=1}^m[f(x^{(i)})-f(G(z^{(i)}))]$ |   $\nabla_{\theta}\frac{1}{m}\sum_{i=1}^m-f(G(z^{(i)}))$   |


约束：$|f(x_1)-f(x_2)| \le |x_1-x_2|$ (叫做1-Lipschitz function)，可以保证函数$f$是比较平滑的(smooth)。

> 1-Lipschitz function：
> $$
> |f(x_1)-f(x_2)| \le |x_1-x_2| \\ \frac{|f(x_1)-f(x_2)|}{|x_1-x_2|}\le1
> $$
> 也就是在1-Lipschitz function的任意位置的导数都是小于等于1。

WGAN与GAN最主要的区别就是：把GAN的JS Divergence换成了Wasserstein Distance。Wasserstein Distance可以很好的解决两个分布(distribution)没有重叠的带来的问题。





### Wasserstein GAN

**weight clipping**：Force the parameters w between C and -C After parameter update, if  w>c, w= C; if w< -C, w=-C 



## WGAN-Gradient Penalty

WGAN的目标：$|f(x_1)-f(x_2)| \le |x_1-x_2|$

在WGAN-Gradient Penalty中，直接将其写入到损失函数中。
$$
L = \mathbb{E}_{\tilde{x} \sim \mathbb{P}_g}[D(\tilde{x})] - \mathbb{E}_{x \sim \mathbb{P}_r}[D(x)] + \lambda \mathbb{E}_{\tilde{x} \sim \mathbb{P}_\tilde{x}}[(||\nabla_\tilde{x}D(\hat{x})||_2-1)^2]
$$

其中，前两项为GAN原来的损失函数，$\lambda \mathbb{E}_{\tilde{x} \sim \mathbb{P}_\tilde{x}}[(||\nabla_\tilde{x}D(\hat{x})||_2-1)^2]$为Gradient Penalty。

$\hat{x}$ 从$\tilde{x}$与$x$之间取值，t在0和之间。随便取一些值就可以。因为遍历所有的x计算量太大了。
$$
\hat{x}  = t \tilde{x} + (1-t)x, with  0 \le t \le 1
$$



### GAN

```python
# use pyTorch
# 获取真实数据预测值
predr = (D(xr))
# maximize
lossr = - (predr.mean())
# 生成fake data
xf = G(z).detach()
predf = (D(xf))
# minimize 
lossf = (predf.mean())
# 求和
loss_D = lossr + lossf
```

### WGAN-Gradient Penalty

1. Gradient Penalty

   ```python
   def gradient_penalty(D, xr, xf):
       LAMBDA = 0.3
       xf = xf.detach()
       xr = xr.detach()
       # 均值分布
       alpha = torch.rand(batchsz, 1).cuda()
       alpha = alpha.expand_as(xr) # 扩展维度成xr的shape
       # 线性差值
       interpolates = alpha * xr + ((1 - alpha) * xf)
       interpolates.requires_grad_() # 设置它的导数信息，因为需要求导，更新
       disc_interpolates = D(interpolates)
       # D的输出(disc_interpolates)对差值(interpolates)求导
       gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,
                                 grad_outputs=torch.ones_like(disc_interpolates),
                                 create_graph=True, retain_graph=True, only_inputs=True)[0]
       # (gradients.norm(2, dim=1) 二范数
       # -1 再求平方，求均值
       gp = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA
       return gp
   ```

2. 修改loss

   ```python
   # use pyTorch
   # 获取真实数据预测值
   predr = (D(xr))
   # maximize
   lossr = - (predr.mean())
   # 生成fake data
   xf = G(z).detach()
   predf = (D(xf))
   # minimize 
   lossf = (predf.mean())
   # 计算 gradient penalty
   gp = gradient_penalty(D, xr, xf.detach())
   # 求和
   loss_D = lossr + lossf + gp
   ```



---


<div style="display:none;">

### 参考
1. Arjovsky M , Chintala S , Bottou, Léon. Wasserstein GAN[J]. 2017.
2. Gulrajani I , Ahmed F , Arjovsky M , et al. Improved Training of Wasserstein GANs[J]. 2017.

</div> 

